{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "\n",
    "from dataset_utils.text_processing import tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store implications in imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'data/imdb/'\n",
    "out_dir = 'data/imdb_imps/'\n",
    "file = 'minival'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = pickle.load(open('data/imdb_imps/vqa_'+file+'_imps.pkl','rb'))\n",
    "imdb = numpy.load(in_dir+'imdb_'+file+'2014.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_map = {\n",
    " 'ans=0 implies none' : 'logeq',\n",
    " 'ans>0 implies some': 'necessary_condition',\n",
    " 'color mutex': 'mutex',\n",
    " 'color_in_answer_must_be_in_picture': 'necessary_condition',\n",
    " 'n+1': 'mutex',\n",
    " 'noun_in_answer_must_be_in_picture': 'necessary_condition',\n",
    " 'remove_modifier': 'necessary_condition',\n",
    " 'subjectyes': 'logeq',\n",
    " 'what': 'logeq',\n",
    " 'where': 'logeq',\n",
    " 'whereprep': 'logeq',\n",
    " 'wordnet mutex': 'mutex',\n",
    " 'wordnet_adj_mutex': 'mutex',\n",
    " 'xory_no': 'mutex',\n",
    " 'xory_yes': 'logeq',\n",
    " 'yeseqcount': 'logeq'\n",
    "}\n",
    "\n",
    "mp = {\n",
    "  'logeq':[1,0,0],\n",
    "  'necessary_condition':[0,1,0],\n",
    "  'mutex':[0,0,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in imdb[1:]:\n",
    "    key = i['question_id']\n",
    "    \n",
    "    if 0 in [len(v) for v in imps[key].values()]: # if any valid answer doesn't have any implications  \n",
    "        i['is_imps'] = False\n",
    "    else:\n",
    "        i['is_imps'] = True\n",
    "        i['qa_implications'] = imps[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in imdb[1:]:\n",
    "    if i['is_imps']:\n",
    "        qa = i['qa_implications']\n",
    "        i['qa_tokens']={}\n",
    "        i['qa_answers']={}\n",
    "        i['imp_type']={}\n",
    "        for key in qa.keys():\n",
    "            i['qa_tokens'][key] = []\n",
    "            i['qa_answers'][key] = []\n",
    "            i['imp_type'][key] = []\n",
    "            \n",
    "            for imp in qa[key]:\n",
    "                i['qa_tokens'][key].append(tokenize(imp[0]))\n",
    "                i['qa_answers'][key].append(imp[1])\n",
    "                i['imp_type'][key].append(mp[source_map[imp[2]]])\n",
    "\n",
    "        i.pop('qa_implications',None)\n",
    "    \n",
    "    else:\n",
    "        i['qa_tokens']={}\n",
    "        i['qa_answers']={}\n",
    "        for key in set(i['valid_answers']):\n",
    "            i['qa_tokens'][key] = [i['question_tokens']]\n",
    "            i['qa_answers'][key] = [key]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# imp_flag =false if there were only necc implications for some valid answers!\n",
    "\n",
    "count = 0\n",
    "for i in imdb[1:]:\n",
    "    if i['is_imps']:\n",
    "        if 0 in [len(v) for v in i['imp_type'].values()]:\n",
    "            i['is_imps'] = False\n",
    "            i.pop('imp_type',None)\n",
    "            \n",
    "            i['qa_tokens']={}\n",
    "            i['qa_answers']={}\n",
    "            for key in set(i['valid_answers']):\n",
    "                i['qa_tokens'][key] = [i['question_tokens']]\n",
    "                i['qa_answers'][key] = [key]\n",
    "            \n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "count/len(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imdb,open(out_dir+'imdb_'+file+'2014.npy','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Ons for several restrictions in imdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = numpy.load(out_dir+'imdb_'+file+'2014.npy',allow_pickle=True)\n",
    "imdb_ori = numpy.load(in_dir+'imdb_'+file+'2014.npy',allow_pickle=True)\n",
    "q = json.load(open('orig_data/vqa_v2.0/v2_mscoco_'+file+'2014_annotations.json','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and delete previous keys\n",
    "\n",
    "for i in imdb[1:]:\n",
    "    if i['is_imps']:\n",
    "        qa = i['qa_implications']\n",
    "        i['qa_tokens']={}\n",
    "        i['qa_answers']={}\n",
    "        for key in qa.keys():\n",
    "            i['qa_tokens'][key] = []\n",
    "            i['qa_answers'][key] = []\n",
    "            for imp in qa[key]:\n",
    "                i['qa_tokens'][key].append(text_processing.tokenize(imp[0]))\n",
    "                i['qa_answers'][key].append(imp[1])\n",
    "        i.pop('qa_implications',None)\n",
    "    \n",
    "    else:\n",
    "        i['qa_tokens']={}\n",
    "        i['qa_answers']={}\n",
    "        for key in set(i['valid_answers']):\n",
    "            i['qa_tokens'][key] = [i['question_tokens']]\n",
    "            i['qa_answers'][key] = [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "for i in imdb[1:]:\n",
    "    if not i['is_imps']:\n",
    "        for key in i['qa_answers']:\n",
    "            if key not in ['yes','no']:\n",
    "                i['qa_answers'][key] = [mode(i['valid_answers'])[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmap = {}\n",
    "\n",
    "for ann in q['annotations']:\n",
    "    atype = ann['answer_type']\n",
    "    qid = ann['question_id']\n",
    "    qmap[qid] = atype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for i in range(1,len(imdb)):\n",
    "    if not imdb[i]['is_imps'] and qmap[imdb[i]['question_id']] != 'yes/no':\n",
    "        idx.append(i)\n",
    "\n",
    "imdb = numpy.delete(imdb,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in imdb[1:]:\n",
    "    if not i['is_imps'] and qmap[i['question_id']]!='yes/no':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete questions w/o any implications for all valid answers\n",
    "\n",
    "idx = []\n",
    "for i in range(1,len(imdb)):\n",
    "    if not imdb[i]['is_imps']:\n",
    "        idx.append(i)\n",
    "    imdb[i].pop('is_imps')\n",
    "\n",
    "imdb = numpy.delete(imdb,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete questions w/o implications for any valid answers\n",
    "\n",
    "idx = []\n",
    "for i in range(1,len(imdb)):\n",
    "    qa = imdb[i]['qa_answers']\n",
    "    for key in qa.keys():\n",
    "        if len(qa[key])==0 :\n",
    "            idx.append(i)\n",
    "            break\n",
    "\n",
    "imdb = numpy.delete(imdb,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imdb,open(out_dir+'imdb_'+file+'2014.npy','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'data/imdb/'\n",
    "out_dir = 'data/imdb_imps/'\n",
    "file = 'train'\n",
    "\n",
    "imdb = numpy.load(out_dir+'imdb_'+file+'2014.npy',allow_pickle=True)\n",
    "imdb_ori = numpy.load(in_dir+'imdb_'+file+'2014.npy',allow_pickle=True)\n",
    "q = json.load(open('orig_data/vqa_v2.0/v2_mscoco_'+file+'2014_annotations.json','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_types = {}\n",
    "qmap = {}\n",
    "\n",
    "for ann in q['annotations']:\n",
    "    atype = ann['answer_type']\n",
    "    qid = ann['question_id']\n",
    "    qmap[qid] = atype\n",
    "    if atype not in question_types.keys():\n",
    "        question_types[atype] = []\n",
    "    question_types[atype].append(qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Stats original vqa2.0')\n",
    "print('Total number of questions: %d' %(len(q['annotations'])))\n",
    "for key in question_types.keys():\n",
    "    print('%s lenght: %d percentage: %.2f' % (key,len(question_types[key]),100*len(question_types[key])/len(q['annotations'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_question_types = {}\n",
    "\n",
    "for ann in imdb[1:]:\n",
    "    qid = ann['question_id']\n",
    "    atype = qmap[qid]\n",
    "    \n",
    "    if atype not in updated_question_types.keys():\n",
    "        updated_question_types[atype]=[]\n",
    "    updated_question_types[atype].append(qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Stats new dataset:')\n",
    "for key in updated_question_types:\n",
    "    print('%s lenght: %d percentage: %.2f' % (key,len(updated_question_types[key]),100*len(updated_question_types[key])/len(imdb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = ['orig_data/vqa_v2.0/v2_OpenEnded_mscoco_train2014_questions.json',\n",
    "                'orig_data/vqa_v2.0/v2_OpenEnded_mscoco_val2014_questions.json',\n",
    "                'orig_data/vqa_v2.0/v2_OpenEnded_mscoco_test2015_questions.json']\n",
    "out_dir = '../'\n",
    "min_freq = 0\n",
    "vocab_file_name = 'vocabulary_vqa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter()\n",
    "questions = []\n",
    "\n",
    "for idx, input_file in enumerate(input_files):\n",
    "    with open(input_file, 'r') as f:\n",
    "        questions += json.load(f)['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_length = [None]*len(questions)\n",
    "for inx, question in enumerate(questions):\n",
    "    words = tokenize(question['question'])\n",
    "    question_length[inx] = len(words)\n",
    "    word_count.update(words)\n",
    "\n",
    "vocabulary = [w[0] for w in word_count.items() if w[1] >= min_freq]\n",
    "vocabulary.sort()\n",
    "vocabulary = ['<unk>'] + vocabulary\n",
    "\n",
    "len(vocabulary) #from original dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['train','val2train','minival'] #from implications\n",
    "questions_imps = []\n",
    "\n",
    "for file in files:\n",
    "    imps = pickle.load(open('data/imdb_imps/vqa_'+file+'_imps.pkl','rb'))\n",
    "    imdb_ori = numpy.load('data/imdb/imdb_'+file+'2014.npy',allow_pickle=True)\n",
    "\n",
    "    for i in imdb_ori[1:]:\n",
    "        key = i['question_id']\n",
    "        questions_imps += [q[0] for v in imps[key].values() for q in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions_imps:\n",
    "    words = tokenize(question)\n",
    "    word_count.update(words)\n",
    "    \n",
    "vocabulary = [w[0] for w in word_count.items() if w[1] >= min_freq]\n",
    "vocabulary.sort()\n",
    "vocabulary = ['<unk>'] + vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questions_imps),len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = os.path.join(out_dir, vocab_file_name)\n",
    "with open(vocab_file, 'w') as f:\n",
    "    f.writelines([w+'\\n' for w in vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create implications imdb (for augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'data/imdb/'\n",
    "out_dir = 'data/imdb_imps/'\n",
    "file = 'val2train'\n",
    "\n",
    "imps = pickle.load(open(out_dir+'vqa_'+file+'_imps.pkl','rb'))\n",
    "imdb = numpy.load(out_dir+'imdb_'+file+'2014.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_just_imps = [imdb[0].copy()]\n",
    "\n",
    "for i in imdb[1:]:\n",
    "    \n",
    "    if i['is_imps']:\n",
    "        vans = mode(i['valid_answers'])[0][0]\n",
    "\n",
    "        for q,a,implied in zip(i['qa_tokens'][vans],i['qa_answers'][vans],imps[i['question_id']][vans]):\n",
    "            cp = i.copy()\n",
    "            cp.pop('qa_tokens',None)\n",
    "            cp.pop('qa_answers',None)\n",
    "            cp.pop('is_imps',None)\n",
    "            cp['question_str'] = implied[0]\n",
    "            cp['question_tokens'] = q\n",
    "            cp['valid_answers'] = [a for _ in range(10)]\n",
    "            cp['all_answers'] = [a for _ in range(10)]\n",
    "            imdb_just_imps.append(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imdb_just_imps,open(in_dir+'imdb_just_imps'+file+'2014.npy','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imdb_just_imps),len(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_just_imps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for manual annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'data/imdb/'\n",
    "imdb_v = numpy.load(in_dir+'imdb_val2014.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_v = json.load(open('orig_data/vqa_v2.0/v2_mscoco_val2014_annotations.json','rb'))\n",
    "\n",
    "qmap = {}\n",
    "    \n",
    "for ann in q_v['annotations']:\n",
    "    atype = ann['answer_type']\n",
    "    qid = ann['question_id']\n",
    "    qmap[qid] = atype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_set = set()\n",
    "for i in imdb_man[1:]:\n",
    "    _set.add(i['question_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = []\n",
    "for i in imdb_v[1:]:\n",
    "    if qmap[i['question_id']] !='yes/no' and i['question_id'] not in _set:\n",
    "        imdb.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "sel = random.sample(imdb,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in sel:\n",
    "    qid = i['question_id']\n",
    "    q = i['question_str']\n",
    "    a = mode(i['valid_answers'])[0][0]\n",
    "    if a not in ['unknown','<unk>']:\n",
    "        data.append({'qid':qid,'question':q,'answer':a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df['Logeq'] = \"\"\n",
    "df['Necc'] = \"\"\n",
    "df['Mutex'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = 'manualAnnotations_new/'\n",
    "for day in numpy.arange(8):\n",
    "    i=1200*day\n",
    "    df[i:400+i].to_excel(direc+str(day+1)+'_1.xlsx')\n",
    "    df[400+i:800+i].to_excel(direc+str(day+1)+'_2.xlsx')\n",
    "    df[800+i:1200+i].to_excel(direc+str(day+1)+'_3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(direc+'all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual to imdb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_list = []\n",
    "for i in range(1,5):\n",
    "\n",
    "    _1 = pd.read_excel('manualAnnotations/day{}_1.xlsx'.format(i),index_col=0)\n",
    "    _1.dropna(inplace=True)\n",
    "    _2 = pd.read_excel('manualAnnotations/day{}_2.xlsx'.format(i),index_col=0)\n",
    "    _2.dropna(inplace=True)\n",
    "    _3 = pd.read_excel('manualAnnotations/day{}_3.xlsx'.format(i),index_col=0)\n",
    "    _3.dropna(inplace=True)\n",
    "    _list.extend([_1,_2,_3])\n",
    "data = pd.concat(_list,sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('manAnnot/QA_from_val.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_val = numpy.load('data/imdb/imdb_val2014.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logeq</th>\n",
       "      <th>Mutex</th>\n",
       "      <th>Necc</th>\n",
       "      <th>answer</th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is this dude using knife to cut the cake?</td>\n",
       "      <td>is this dude using a hammer to cut the cake?</td>\n",
       "      <td>is there any cake in the picture?</td>\n",
       "      <td>knife</td>\n",
       "      <td>340069003</td>\n",
       "      <td>This bored dude is using what instrument to cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is a city bus pictured?</td>\n",
       "      <td>is the type of bus  pictured a tourist bus?</td>\n",
       "      <td>is there a bus pictured?</td>\n",
       "      <td>city bus</td>\n",
       "      <td>188817001</td>\n",
       "      <td>What type of bus is pictured?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>are there logs on the ground behind the giraffe?</td>\n",
       "      <td>is there spoon laying on the ground behind the...</td>\n",
       "      <td>is there a giraffe?</td>\n",
       "      <td>logs</td>\n",
       "      <td>573778003</td>\n",
       "      <td>What is laying on the ground behind the giraffe?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is the horse brown?</td>\n",
       "      <td>is the horse black?</td>\n",
       "      <td>is there a  horse?</td>\n",
       "      <td>brown</td>\n",
       "      <td>405135001</td>\n",
       "      <td>What color is the horse?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is the surfboard green?</td>\n",
       "      <td>is the surfboard yellow?</td>\n",
       "      <td>is there a surfboard?</td>\n",
       "      <td>green</td>\n",
       "      <td>187362006</td>\n",
       "      <td>What color is the surfboard?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>is the man talking into a microphone?</td>\n",
       "      <td>is the man talking into a phone?</td>\n",
       "      <td>is the man talking into anything?</td>\n",
       "      <td>microphone</td>\n",
       "      <td>196742000</td>\n",
       "      <td>What is the man talking into?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>is a bike in between the trees and the parking...</td>\n",
       "      <td>is a car in between the trees and the parking ...</td>\n",
       "      <td>is anything in between the trees and the parki...</td>\n",
       "      <td>bike</td>\n",
       "      <td>152771012</td>\n",
       "      <td>What is in between the trees and the parking s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>is the gray, white, and black item in the righ...</td>\n",
       "      <td>is the gray, white, and black item in the righ...</td>\n",
       "      <td>is there a gray, white, and black item in the ...</td>\n",
       "      <td>backpack</td>\n",
       "      <td>357604002</td>\n",
       "      <td>What is the gray, white, and black item in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>are 4 birds on the posts?</td>\n",
       "      <td>are 5 birds on the posts?</td>\n",
       "      <td>are birds on the posts?</td>\n",
       "      <td>4</td>\n",
       "      <td>553790006</td>\n",
       "      <td>How many birds are on the posts?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>is the guy wearing a backpack on his back?</td>\n",
       "      <td>is the guy wearing a suitcase on his back?</td>\n",
       "      <td>is the guy wearing a backpack?</td>\n",
       "      <td>backpack</td>\n",
       "      <td>467116001</td>\n",
       "      <td>What is the guy wearing on his back?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10321 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Logeq  \\\n",
       "0             is this dude using knife to cut the cake?   \n",
       "3                               is a city bus pictured?   \n",
       "8      are there logs on the ground behind the giraffe?   \n",
       "10                                  is the horse brown?   \n",
       "11                              is the surfboard green?   \n",
       "...                                                 ...   \n",
       "8395              is the man talking into a microphone?   \n",
       "8396  is a bike in between the trees and the parking...   \n",
       "8397  is the gray, white, and black item in the righ...   \n",
       "8398                          are 4 birds on the posts?   \n",
       "8399         is the guy wearing a backpack on his back?   \n",
       "\n",
       "                                                  Mutex  \\\n",
       "0          is this dude using a hammer to cut the cake?   \n",
       "3           is the type of bus  pictured a tourist bus?   \n",
       "8     is there spoon laying on the ground behind the...   \n",
       "10                                  is the horse black?   \n",
       "11                             is the surfboard yellow?   \n",
       "...                                                 ...   \n",
       "8395                   is the man talking into a phone?   \n",
       "8396  is a car in between the trees and the parking ...   \n",
       "8397  is the gray, white, and black item in the righ...   \n",
       "8398                          are 5 birds on the posts?   \n",
       "8399         is the guy wearing a suitcase on his back?   \n",
       "\n",
       "                                                   Necc      answer  \\\n",
       "0                     is there any cake in the picture?       knife   \n",
       "3                              is there a bus pictured?    city bus   \n",
       "8                                   is there a giraffe?        logs   \n",
       "10                                   is there a  horse?       brown   \n",
       "11                                is there a surfboard?       green   \n",
       "...                                                 ...         ...   \n",
       "8395                  is the man talking into anything?  microphone   \n",
       "8396  is anything in between the trees and the parki...        bike   \n",
       "8397  is there a gray, white, and black item in the ...    backpack   \n",
       "8398                            are birds on the posts?           4   \n",
       "8399                     is the guy wearing a backpack?    backpack   \n",
       "\n",
       "            qid                                           question  \n",
       "0     340069003  This bored dude is using what instrument to cu...  \n",
       "3     188817001                      What type of bus is pictured?  \n",
       "8     573778003   What is laying on the ground behind the giraffe?  \n",
       "10    405135001                           What color is the horse?  \n",
       "11    187362006                       What color is the surfboard?  \n",
       "...         ...                                                ...  \n",
       "8395  196742000                      What is the man talking into?  \n",
       "8396  152771012  What is in between the trees and the parking s...  \n",
       "8397  357604002  What is the gray, white, and black item in the...  \n",
       "8398  553790006                   How many birds are on the posts?  \n",
       "8399  467116001               What is the guy wearing on his back?  \n",
       "\n",
       "[10321 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_man = [imdb_val[0].copy()]\n",
    "\n",
    "for _,d in data.iterrows():\n",
    "    entry = {}\n",
    "    qid = d['qid']\n",
    "    image_id = int(qid/1000)\n",
    "    \n",
    "    entry['image_name'] = 'COCO_val2014_'+str(image_id).zfill(12)\n",
    "    entry['image_id'] = image_id\n",
    "    entry['feature_path'] = 'COCO_val2014_'+str(image_id).zfill(12)+'.npy'\n",
    "    \n",
    "    for i,(q, a) in enumerate(zip(['Logeq','Necc','Mutex'],['yes','yes','no'])):\n",
    "        entry['question_id'] = qid*10+(i+1)\n",
    "        entry['question_str'] = d[q]\n",
    "        entry['question_tokens'] = tokenize(d[q])\n",
    "        entry['valid_answers'] = [a for _ in range(10)]\n",
    "        entry['all_answers'] = [a for _ in range(10)]\n",
    "        imdb_man.append(entry.copy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imdb_man,open('data/imdb_manual/imdb_val2014.npy','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_name': 'COCO_val2014_000000340069',\n",
       " 'image_id': 340069,\n",
       " 'feature_path': 'COCO_val2014_000000340069.npy',\n",
       " 'question_id': 3400690031,\n",
       " 'question_str': 'is this dude using knife to cut the cake?',\n",
       " 'question_tokens': ['is',\n",
       "  'this',\n",
       "  'dude',\n",
       "  'using',\n",
       "  'knife',\n",
       "  'to',\n",
       "  'cut',\n",
       "  'the',\n",
       "  'cake'],\n",
       " 'valid_answers': ['yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes'],\n",
       " 'all_answers': ['yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_man[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4426"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for i in imdb_val[1:]:\n",
    "    a = mode(i['valid_answers'])[0][0]\n",
    "    if a in ['unknown','<unk>']:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02064799048307714"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c/len(imdb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
