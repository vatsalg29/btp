{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = numpy.load('data/imdb/imdb_val2014.npy',allow_pickle=True)\n",
    "\n",
    "base_pred = json.load(open('results/default/30/' + 'Pythia_val.json','r'))\n",
    "model_pred = json.load(open('results/pythia_cycle_consistent/3014/' + 'Pythia_IC_val.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_map = {}\n",
    "model_map = {}\n",
    "\n",
    "for val in base_pred:\n",
    "    base_map[val['question_id']] = val['answer']\n",
    "    \n",
    "for val in model_pred:\n",
    "    model_map[val['question_id']] = val['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_imdb = []\n",
    "for item in imdb[1:]:\n",
    "    ques = item['question_tokens']\n",
    "    if 'do' in ques and 'you' in ques and 'see' in ques and 'a' in ques:\n",
    "        bias_imdb.append(item)\n",
    "len(bias_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "base_count = 0\n",
    "model_count = 0\n",
    "for item in bias_imdb:\n",
    "    q_id = item['question_id']\n",
    "    base_answer = base_map[q_id]\n",
    "    model_answer = model_map[q_id]\n",
    "    bias_answer = 'yes'\n",
    "    if base_answer == bias_answer:\n",
    "        base_count +=1\n",
    "    if model_answer == bias_answer:\n",
    "        model_count +=1\n",
    "#     if base_answer == bias_answer or model_answer == bias_answer:\n",
    "#         imgId = item['image_id']\n",
    "#         imgFilename = 'orig_data/vqa_v2.0/val2014/' + 'COCO_val2014_'+ str(imgId).zfill(12) + '.jpg'\n",
    "\n",
    "#         if os.path.isfile(imgFilename):\n",
    "#             I = io.imread(imgFilename)\n",
    "#             plt.imshow(I)\n",
    "#             plt.axis('off')\n",
    "#             plt.show()\n",
    "#         print(item['question_str'])\n",
    "#         print(\"Baseline Answer = \", base_answer)\n",
    "#         print(\"Model Answer = \", model_answer)\n",
    "print(base_count)\n",
    "print(model_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
