{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store impl in imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'data/imdb/'\n",
    "out_dir = 'data/imdb_imps/'\n",
    "file = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = pickle.load(open(out_dir+'vqa_'+file+'_imps.pkl','rb'))\n",
    "imdb_ori = numpy.load(in_dir+'imdb_'+file+'2014.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(imdb_ori)):\n",
    "    key = imdb_ori[i]['question_id']\n",
    "    if sum([len(v) for v in imps[key].values()])==0:\n",
    "        imdb_ori[i]['is_imps'] = False\n",
    "    else:\n",
    "        imdb_ori[i]['is_imps'] = True\n",
    "        imdb_ori[i]['qa_implications'] = imps[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imdb_ori,open(out_dir+'imdb_'+file+'2014.npy','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizing qa_imps and deleting entries w/o imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import text_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = numpy.load(out_dir+'imdb_'+file+'2014.npy',allow_pickle=True)\n",
    "imdb_ori = numpy.load(in_dir+'imdb_'+file+'2014.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and delete previous keys\n",
    "\n",
    "for i in range(1,len(imdb)):\n",
    "    if imdb[i]['is_imps']:\n",
    "        qa = imdb[i]['qa_implications']\n",
    "        imdb[i]['qa_tokens']={}\n",
    "        imdb[i]['qa_answers']={}\n",
    "        for key in qa.keys():\n",
    "            imdb[i]['qa_tokens'][key] = []\n",
    "            imdb[i]['qa_answers'][key] = []\n",
    "            for imp in qa[key]:\n",
    "                imdb[i]['qa_tokens'][key].append(text_processing.tokenize(imp[0]))\n",
    "                imdb[i]['qa_answers'][key].append(imp[1])\n",
    "        imdb[i].pop('qa_implications',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete questions w/o any implications for all valid answers\n",
    "\n",
    "idx = []\n",
    "for i in range(1,len(imdb)):\n",
    "    if not imdb[i]['is_imps']:\n",
    "        idx.append(i)\n",
    "    imdb[i].pop('is_imps')\n",
    "\n",
    "imdb = numpy.delete(imdb,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete questions w/o implications for any valid answers\n",
    "\n",
    "idx = []\n",
    "for i in range(1,len(imdb)):\n",
    "    qa = imdb[i]['qa_answers']\n",
    "    for key in qa.keys():\n",
    "        if len(qa[key])==0 :\n",
    "            idx.append(i)\n",
    "            break\n",
    "\n",
    "imdb = numpy.delete(imdb,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imdb,open(out_dir+'imdb_'+file+'2014.npy','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imdb),len(imdb_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "t = random.choice(list(imdb[1]['qa_tokens'].items()))\n",
    "np.random.choice(len(imdb[1]['qa_tokens'][t[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_answers = imdb[3]['valid_answers']\n",
    "for i in range(0,len(valid_answers)):\n",
    "    valid_answers[i] = 'yes'\n",
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(imdb)):\n",
    "    if len(imdb[i]['valid_answers']) != 10:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = numpy.load(out_dir+'imdb_'+file+'2014.npy',allow_pickle=True)\n",
    "imdb_ori = numpy.load(in_dir+'imdb_'+file+'2014.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(imdb)):\n",
    "    if imdb[i]['question_id']==458752001:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = imdb[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iminfo = imdb[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']\n",
      "c\n",
      "['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(\"b\")\n",
    "print(iminfo['valid_answers'])\n",
    "\n",
    "imp_valid_answers = iminfo['valid_answers']\n",
    "# for i in range(0,len(imp_valid_answers)):\n",
    "#     imp_valid_answers[i] = 'yes'\n",
    "imp_valid_answers = ['yes']\n",
    "print(\"c\")\n",
    "print(iminfo['valid_answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_name': 'COCO_train2014_000000458752',\n",
       " 'image_id': 458752,\n",
       " 'question_id': 458752001,\n",
       " 'feature_path': 'COCO_train2014_000000458752.npy',\n",
       " 'question_str': 'What position is this man playing?',\n",
       " 'question_tokens': ['what', 'position', 'is', 'this', 'man', 'playing'],\n",
       " 'all_answers': ['pitcher',\n",
       "  'catcher',\n",
       "  'pitcher',\n",
       "  'pitcher',\n",
       "  'pitcher',\n",
       "  'pitcher',\n",
       "  'pitcher',\n",
       "  'pitcher',\n",
       "  'pitcher',\n",
       "  'pitcher'],\n",
       " 'valid_answers': ['yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes',\n",
       "  'yes'],\n",
       " 'qa_tokens': {'pitcher': [['is', 'this', 'man', 'playing', 'the', 'pitcher']],\n",
       "  'catcher': [['is', 'this', 'man', 'playing', 'a', 'catcher']]},\n",
       " 'qa_answers': {'pitcher': ['yes'], 'catcher': ['yes']}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/btp/pg_aa_1/.conda/envs/test/lib/python3.8/site-packages/tensorboardX-1.2-py3.8.egg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/BTP/pg_aa_1/btp/config/config_utils.py:86: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  updates = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from train_model.dataset_utils import prepare_test_data_set,prepare_eval_data_set,prepare_train_data_set\n",
    "import torch\n",
    "from train_model.helper import run_model, print_result, build_model\n",
    "from config.config_utils import finalize_config\n",
    "from config.config import cfg\n",
    "\n",
    "config_file = 'results/pythia_cycle_consistent/2020/config.yaml'\n",
    "model_file = 'results/pythia_cycle_consistent/2020/best_model.pth'\n",
    "finalize_config(cfg, config_file, None)\n",
    "\n",
    "batch_size = cfg['data']['batch_size']\n",
    "\n",
    "data= prepare_train_data_set(**cfg['data'], **cfg['model'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg['data']['imdb_file_train'] = ['imdb_imps/imdb_val2train2014.npy']\n",
    "cfg['data']['image_feat_train'] = ['detectron_fix_100/fc6/vqa/val2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "while(c<10000):\n",
    "    c+=1\n",
    "    try:\n",
    "        print(data_set_test[4])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <listcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\nKeyError: 'red'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a8e2f2ac2c20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_reader_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_reader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\", line 74, in <listcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\nKeyError: 'red'\n"
     ]
    }
   ],
   "source": [
    "data_reader_test = DataLoader(data, shuffle=True, batch_size=2, num_workers=1,drop_last=True)\n",
    "for idx,batch in enumerate(data_reader_test):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'yield' outside function (<ipython-input-17-b86a004ba169>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-b86a004ba169>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    yield data_reader_test.collate_fn(data[idx])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'yield' outside function\n"
     ]
    }
   ],
   "source": [
    "for idx in [0,1,2,3]:\n",
    "    yield data_reader_test.collate_fn(data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38494, 4096)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_reader_test),batch_size*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f2ef2d912100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_reader_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;34mr\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
